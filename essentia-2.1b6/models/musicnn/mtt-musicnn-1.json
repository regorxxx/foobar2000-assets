{
    "name": "MTT MusiCNN",
    "type": "auto-tagging",
    "link": "https://essentia.upf.edu/models/autotagging/mtt/mtt-musicnn-1.pb",
    "version": "1",
    "description": "prediction of the top-50 tags in the dataset",
    "author": "Pablo Alonso",
    "email": "pablo.alonso@upf.edu",
    "release_date": "2020-03-31",
    "framework": "tensorflow",
    "framework_version": "1.15.0",
    "classes": [
        "guitar",
        "classical",
        "slow",
        "techno",
        "strings",
        "drums",
        "electronic",
        "rock",
        "fast",
        "piano",
        "ambient",
        "beat",
        "violin",
        "vocal",
        "synth",
        "female",
        "indian",
        "opera",
        "male",
        "singing",
        "vocals",
        "no vocals",
        "harpsichord",
        "loud",
        "quiet",
        "flute",
        "woman",
        "male vocal",
        "no vocal",
        "pop",
        "soft",
        "sitar",
        "solo",
        "man",
        "classic",
        "choir",
        "voice",
        "new age",
        "dance",
        "male voice",
        "female vocal",
        "beats",
        "harp",
        "cello",
        "no voice",
        "weird",
        "country",
        "metal",
        "female voice",
        "choral"
    ],
    "model_types": [
        "frozen_model"
    ],
    "dataset": {
        "name": "The MagnaTagATune dataset",
        "citation": "http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset",
        "size": "20k tracks",
        "metrics": {
            "ROC-AUC": 0.91,
            "PR-AUC": 0.38
        }
    },
    "schema": {
        "inputs": [
            {
                "name": "model/Placeholder",
                "type": "float",
                "shape": [
                    187,
                    96
                ]
            }
        ],
        "outputs": [
            {
                "name": "model/Sigmoid",
                "type": "float",
                "shape": [
                    1,
                    50
                ],
                "op": "Sigmoid",
                "output_purpose": "predictions"
            },
            {
                "name": "model/dense_1/BiasAdd",
                "type": "float",
                "shape": [
                    1,
                    50
                ],
                "op": "fully connected",
                "description": "logits",
                "output_purpose": ""
            },
            {
                "name": "model/dense/BiasAdd",
                "type": "float",
                "shape": [
                    1,
                    200
                ],
                "op": "fully connected",
                "output_purpose": "embeddings"
            }
        ]
    },
    "citation": "@inproceedings{alonso2020tensorflow,\n  title={Tensorflow Audio Models in Essentia},\n  author={Alonso-Jim{\\'e}nez, Pablo and Bogdanov, Dmitry and Pons, Jordi and Serra, Xavier},\n  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n  year={2020}\n}",
    "inference": {
        "sample_rate": 16000,
        "algorithm": "TensorflowPredictMusiCNN"
    }
}